{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# MOVID Video Detect\n",
    "MOVID: Mask Object Visualize Identification Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('movid_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimhy\\K-Digital MLDL\\Semi-project3\\4팀\\maskdata\\knowns\n"
     ]
    }
   ],
   "source": [
    "cd ../maskdata/knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'os.getcwd()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경로 확인\n",
    "curr_path = 'os.getcwd()'\n",
    "curr_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hyojin.jpg', 'Lenna.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 미리 등록된 얼굴정보 경로에 어떤 파일이 있는지 확인\n",
    "known_face_dir = os.listdir('./')\n",
    "known_face_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아는 얼굴들 미리 모아놓기\n",
    "\n",
    "known_face_encodings = []\n",
    "known_user_names = []\n",
    "error_user_list = []\n",
    "\n",
    "for known_face_user in known_face_dir:\n",
    "    \n",
    "    known_user_image = face_recognition.load_image_file(known_face_user)\n",
    "    \n",
    "    try:\n",
    "        known_user_encoding = face_recognition.face_encodings(known_user_image)[0]\n",
    "        known_face_encodings.append(known_user_encoding)\n",
    "        known_user_names.append(known_face_user[:-4])\n",
    "        \n",
    "    except:\n",
    "        print(f\"{known_face_user[:-4]}의 얼굴인식이 되지 않습니다.재촬영이 필요합니다.\")\n",
    "        error_user_list.append(known_face_user)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def known_face_name(frame, known_face_encodings, known_user_names):\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    process_this_frame = True\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # 얼굴 인식 처리 속도를 높이기 위해 비디오 프레임 크기를 1/4 크기로 조정\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # 영상을 BGR 색상(OpenCV가 사용하는)에서 RGB 색상(페이스_인식 사용)으로 변환\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # 다른 모든 비디오 프레임만 처리하여 시간 절약\n",
    "    if process_this_frame:\n",
    "        # 현재 비디오 프레임에서 모든 얼굴 및 얼굴 인코딩 찾기\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 얼굴이 known face(s)와 일치하는지 확인\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            \n",
    "            # # known_face_encodings에서 일치하는 항목이 발견되면 첫 번째 항목을 사용\n",
    "            # 일치하는 경우:\n",
    "            # first_match_index =이(가) 일치합니다.index(참)\n",
    "            # name = knowled_face_names[first_match_index]\n",
    "\n",
    "            # 대신 새 얼굴까지의 거리가 가장 작은 알려진 얼굴을 사용합니다.\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_user_names[best_match_index]\n",
    "\n",
    "        return name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimhy\\K-Digital MLDL\\Semi-project3\\4팀\\maskdata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kimhy\\\\K-Digital MLDL\\\\Semi-project3\\\\4팀\\\\maskdata'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "curr_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 실시간 마스크 착용여부 탐지\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 마스크 미착용자 정보 저장할 리스트\n",
    "nomask_info = []\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')    \n",
    "out = cv2.VideoWriter('save.avi', fourcc, 25.0, (640, 480)) \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    " \n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        # 얼굴 영역\n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "            \n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            # 모델에 넣을 수 있게 처리\n",
    "            x = img_to_array(face_region1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            # 모델에 넣기\n",
    "            prediction = model.predict(x)\n",
    "            \n",
    "            # 등록된 사람인지 확인\n",
    "            result_name = known_face_name(frame, known_face_encodings, known_user_names)\n",
    "#             print(result_name)\n",
    " \n",
    "            if prediction < 0.5: # 마스크 미착용으로 판별되면,\n",
    "        \n",
    "                # display text (ex-> name is No Mask 98.34%)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"No Mask ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
    "                result_text = result_name + \" is \" + text\n",
    "                cv2.putText(frame, result_text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                \n",
    "                # 사용자에 따라서 폴더 만들기\n",
    "                nomask_capture_path = './nomask_capture/'\n",
    "                now_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S') \n",
    "                name_path = nomask_capture_path + result_name\n",
    "#                 print(\"name_path->>>>\", name_path)\n",
    "                \n",
    "                # 사용자 이름 폴더 없으면 생성\n",
    "                if not os.path.exists(name_path):\n",
    "                    os.mkdir(name_path)\n",
    "                \n",
    "                # 이미지 저장\n",
    "                img_name = f\"{name_path}/{result_name}{now_time}.png\".format(name_path, result_name, now_time)\n",
    "                cv2.imwrite(img_name, frame)    \n",
    "#                 print(img_name)\n",
    "                out.write(frame)\n",
    "                # 사용자 정보 저장\n",
    "                nomask_info.append((result_name, now_time))\n",
    "\n",
    "#                 os.chdir('../')\n",
    "                \n",
    "            else: # 마스크 착용으로 판별되면 (ex-> name is Mask 98.33%)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"Mask ({:.2f}%)\".format(prediction[0][0]*100)\n",
    "                result_text = result_name + \" is \" + text\n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                \n",
    "    # display output\n",
    "    cv2.imshow(\"MOVID_Mask_Detector\", frame)\n",
    " \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        df = pd.DataFrame(nomask_info, columns=['name', 'date_time'])\n",
    "        \n",
    "        list_path = curr_path + '\\\\nomask_list'\n",
    "        print(\"listPath->>\", list_path)\n",
    "        if not os.path.isdir(list_path):                                                           \n",
    "            os.mkdir(list_path)\n",
    "            \n",
    "        df.to_excel('{}\\\\nomask_list_{}.xlsx'.format(list_path, datetime.now().strftime('%Y_%m_%d')))\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release resources\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## 실시간 마스크 착용여부 탐지(+비디오 저장)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 마스크 미착용자 정보 저장할 리스트\n",
    "nomask_info = []\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    " \n",
    "status, frame = webcam.read()\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('record.mp4', fourcc, webcam.get(cv2.CAP_PROP_FPS), (frame.shape[1], frame.shape[0]))\n",
    " \n",
    " \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "\n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    " \n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        # 얼굴 영역\n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "            \n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            # 모델에 넣을 수 있게 처리\n",
    "            x = img_to_array(face_region1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            # 모델에 넣기\n",
    "            prediction = model.predict(x)\n",
    "            \n",
    "            # 등록된 사람인지 확인\n",
    "            result_name = known_face_name(frame, known_face_encodings, known_user_names)\n",
    "#                 print(result_name)          \n",
    "\n",
    "            if prediction < 0.5: # 마스크 미착용으로 판별되면,         \n",
    "                # display text (ex-> name is No Mask 98.34%)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"No Mask ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
    "                result_text = result_name + \" is \" + text\n",
    "                cv2.putText(frame, result_text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "            \n",
    "                # 사용자에 따라서 폴더 만들기\n",
    "                nomask_capture_path = './nomask_capture/'\n",
    "                now_time = datetime.now().strftime('%Y_%m_%d_%H_%M_%S') \n",
    "                name_path = nomask_capture_path + result_name\n",
    "#                 print(\"name_path->>>>\", name_path)\n",
    "                \n",
    "                # 사용자 이름 폴더 없으면 생성\n",
    "                if not os.path.isdir(name_path):\n",
    "                    os.mkdir(name_path)\n",
    "                \n",
    "                # 이미지 저장\n",
    "                img_name = f\"{name_path}/{result_name}{now_time}.png\".format(name_path, result_name, now_time)\n",
    "                cv2.imwrite(img_name, frame)    \n",
    "#                 print(img_name)\n",
    "                # 사용자 정보 저장\n",
    "                nomask_info.append((result_name, now_time))\n",
    "\n",
    "#                 os.chdir('../')\n",
    "                \n",
    "            else: # 마스크 착용으로 판별되면 (ex-> name is Mask 98.33%)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"Mask ({:.2f}%)\".format(prediction[0][0]*100)\n",
    "                result_text = result_name + \" is \" + text                \n",
    "                cv2.putText(frame, text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                \n",
    "    # display output\n",
    "    cv2.imshow(\"MOVID_Mask_Detector\", frame)\n",
    "    out.write(frame) \n",
    "    \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        df = pd.DataFrame(nomask_info, columns=['name', 'date_time'])\n",
    "        \n",
    "        list_path = curr_path + '/nomask_list/'\n",
    "        print(\"listPath->>\", list_path)\n",
    "        if not os.path.isdir(list_path):                                                           \n",
    "            os.mkdir(list_path)\n",
    "            \n",
    "        df.to_excel('{}nomask_list_{}.xlsx'.format(list_path, datetime.now().strftime('%Y_%m_%d')))\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "out.release()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release resources\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_36_dlib",
   "language": "python",
   "name": "python_36_dlib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
