{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Make Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#사진데이터 전처리 일반적인 얼굴을 구함\n",
    "1. Face Detection\n",
    "2. Landmark Detection\n",
    "3. 배경은 투명인 마스크이미지를 landmark 기준으로 얼굴에 붙임(눈과 코를 기준)\n",
    "4. 마스크를 안쓴 이미지 -> 마스크를 쓴 이미지\n",
    "   다양한 이미지 사용. 사람들 이미지수를 늘리는지해서 Dataset을 만듦\n",
    "\n",
    "5. 모델구조(전이학습)\n",
    "2개의 아웃풋[0 , 0]\n",
    "softmax를 통해 마스크썻으면 1,0 마스크 안썻으면 0,1 \n",
    "cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimhy\\K-Digital MLDL\\Semi-project3\\4팀\\maskdata\n"
     ]
    }
   ],
   "source": [
    "cd ./maskdata/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    " \n",
    "# 마스크데이터 \n",
    "path_dir1 = './Non_Mask/'\n",
    "path_dir2 = './Mask/'\n",
    "\n",
    "# path에 존재하는 파일 목록 가져오기\n",
    "file_list1 = os.listdir(path_dir1)\n",
    "file_list2 = os.listdir(path_dir2)\n",
    " \n",
    "file_list1_num = len(file_list1)\n",
    "file_list2_num = len(file_list2)\n",
    " \n",
    "file_num = file_list1_num + file_list2_num\n",
    " \n",
    " \n",
    "#이미지 전처리\n",
    "# https://ivo-lee.tistory.com/91\n",
    "num = 0;\n",
    "all_img = np.float32(np.zeros((file_num, 224, 224, 3))) # zeros는 0으로 가득 찬 array를 생성합니다. # np.zeros(shape, dtype, order) dtype default = float64, order는 저장할때 다차원 순서\n",
    "all_label = np.float64(np.zeros((file_num, 1))) #0아니면 1 할거라서 64?\n",
    " \n",
    "for img_name in file_list1:\n",
    "    img_path = path_dir1 + img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :, :] = x\n",
    "    \n",
    "    all_label[num] = 0 # nomask\n",
    "    num = num + 1\n",
    " \n",
    "for img_name in file_list2:\n",
    "    img_path = path_dir2+img_name\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    all_img[num, :, :, :] = x\n",
    "    \n",
    "    all_label[num] = 1 # mask\n",
    "    num = num + 1\n",
    " \n",
    " \n",
    "# 데이터셋 섞기(적절하게 훈련되게 하기 위함) \n",
    "n_elem = all_label.shape[0]\n",
    "indices = np.random.choice(n_elem, size=n_elem, replace=False)\n",
    " \n",
    "all_label = all_label[indices]\n",
    "all_img = all_img[indices]\n",
    " \n",
    " \n",
    "# 훈련셋 테스트셋 분할\n",
    "num_train = int(np.round(all_label.shape[0]*0.8))\n",
    "num_test = int(np.round(all_label.shape[0]*0.2))\n",
    " \n",
    "train_img = all_img[0:num_train, :, :, :]\n",
    "test_img = all_img[num_train:, :, :, :] \n",
    " \n",
    "train_label = all_label[0:num_train]\n",
    "test_label = all_label[num_train:]\n",
    " \n",
    " \n",
    "# create the base pre-trained model\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    " \n",
    "base_model = ResNet50(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)\n",
    "base_model.trainable = False\n",
    "base_model.summary()\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    " \n",
    "flatten_layer = Flatten()\n",
    "dense_layer1 = Dense(128, activation='relu')\n",
    "bn_layer1 = BatchNormalization()\n",
    "dense_layer2 = Dense(1, activation=tf.nn.sigmoid)\n",
    " \n",
    "model = Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer1,\n",
    "        bn_layer1,\n",
    "        dense_layer2,\n",
    "        ])\n",
    " \n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "model.fit(train_img, train_label, epochs=10, batch_size=16, validation_data = (test_img, test_label))\n",
    " \n",
    " \n",
    "\n",
    "# save model\n",
    "model.save(\"model.h5\")\n",
    " \n",
    "print(\"Saved model to disk\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_36_dlib",
   "language": "python",
   "name": "python_36_dlib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
