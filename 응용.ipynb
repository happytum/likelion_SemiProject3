{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 36,433,537\n",
      "Trainable params: 36,380,161\n",
      "Non-trainable params: 53,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    " \n",
    " \n",
    "model = load_model('model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimhy\\K-Digital MLDL\\Semi-project3\\4팀\\maskdata\\face_recognition\\knowns\n"
     ]
    }
   ],
   "source": [
    "cd maskdata/face_recognition/knowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_dir = os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# ## 이미지 크기 바꿔서 저장해주는 함수\n",
    "# def change_img_size(img_list_name, size):\n",
    "# #     print(f\"\\n{dir_name}의 이미지 변환 시작\")\n",
    "#     for img_name in img_list_name:\n",
    "#         image_data = Image.open(img_name)\n",
    "# #         image_size = image_data.size\n",
    "#         # print(image_size) # 궁금하다면 주석 풀기\n",
    "#         image_resize = image_data.resize(size)\n",
    "#         # print(image_resize)\n",
    "#         # print(image_resize.size)\n",
    "#         image_resize.save(img_name)\n",
    "\n",
    "# change_img_size(known_face_dir, (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyojinkim의 얼굴인식이 되지 않습니다.재촬영이 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "# 아는 얼굴들 미리 모아놓기\n",
    "\n",
    "known_face_encodings = []\n",
    "known_user_names = []\n",
    "error_user_list = []\n",
    "for known_face_user in known_face_dir:\n",
    "    known_user_image = face_recognition.load_image_file(known_face_user)\n",
    "    try:\n",
    "        known_user_encoding = face_recognition.face_encodings(known_user_image)[0]\n",
    "        known_face_encodings.append(known_user_encoding)\n",
    "        known_user_names.append(known_face_user[:-4])\n",
    "    except: # 얼굴인식이 안되는 사진들은 리스트에 넣어지지않도록 따로 분리\n",
    "        print(f\"{known_face_user[:-4]}의 얼굴인식이 되지 않습니다.재촬영이 필요합니다.\")\n",
    "        error_user_list.append(known_face_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cvlib as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import ImageFont, ImageDraw, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아는 얼굴 찾기\n",
    "def known_face_name(frame, known_face_encodings, known_user_names):\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    process_this_frame = True\n",
    "    name = ''\n",
    "    # 얼굴 인식 처리 속도를 높이기 위해 비디오 프레임 크기를 1/4 크기로 조정\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # 영상을 BGR 색상(OpenCV가 사용하는)에서 RGB 색상(페이스_인식 사용)으로 변환\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # 다른 모든 비디오 프레임만 처리하여 시간 절약\n",
    "    if process_this_frame:\n",
    "        # 현재 비디오 프레임에서 모든 얼굴 및 얼굴 인코딩 찾기\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 얼굴이 known face(s)와 일치하는지 확인\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # # known_face_encodings에서 일치하는 항목이 발견되면 첫 번째 항목을 사용\n",
    "            # 일치하는 경우:\n",
    "            # first_match_index =이(가) 일치합니다.index(참)\n",
    "            # name = knowled_face_names[first_match_index]\n",
    "\n",
    "            # 대신 새 얼굴까지의 거리가 가장 작은 known 얼굴을 사용\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_user_names[best_match_index]\n",
    "\n",
    "    \n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    " \n",
    " \n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    " \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    " \n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    if not status:\n",
    "        print(\"Could not read frame\")\n",
    "        exit()\n",
    " \n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    " \n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "        \n",
    "        if 0 <= startX <= frame.shape[1] and 0 <= endX <= frame.shape[1] and 0 <= startY <= frame.shape[0] and 0 <= endY <= frame.shape[0]:\n",
    "            \n",
    "            face_region = frame[startY:endY, startX:endX]\n",
    "            \n",
    "            face_region1 = cv2.resize(face_region, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            x = img_to_array(face_region1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            \n",
    "            prediction = model.predict(x)\n",
    " \n",
    "            if prediction < 0.5: # 마스크 미착용으로 판별되면, \n",
    "                result_name = known_face_name(frame, known_face_encodings, known_user_names)\n",
    "#                 print(result_name)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,0,255), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"No Mask ({:.2f}%)\".format((1 - prediction[0][0])*100)\n",
    "                result_text = result_name + \" is \" + text\n",
    "                cv2.putText(frame, result_text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "                now_time = datetime.now().strftime('%Y_%m_%d') #초단위라서 여러장 나옴 #이 위에 중복인물인지 체크하는 함수와 if문으로 저장 필요%H%M%S\n",
    "#                 temp_time = now_time[:17]\n",
    "                img_name = f\"../nomask_capture/{result_name}_{now_time}\" + '.jpg'\n",
    "                cv2.imwrite(img_name, frame)\n",
    "                \n",
    "            else: # 마스크 착용으로 판별되면\n",
    "                result_name = known_face_name(frame, known_face_encodings, known_user_names)\n",
    "#                 print(result_name)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "                Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                text = \"Mask ({:.2f}%)\".format(prediction[0][0]*100)\n",
    "                result_text = result_name + \" is \" + text\n",
    "                cv2.putText(frame, result_text, (startX,Y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "                \n",
    "    # display output\n",
    "    cv2.imshow(\"mask nomask classify\", frame)\n",
    " \n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release resources\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_36_dlib",
   "language": "python",
   "name": "python_36_dlib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
